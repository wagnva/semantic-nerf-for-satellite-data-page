<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Semantic Neural Radiance Fields for Multi-Date Satellite Data">
  <meta name="keywords" content="Semantic, Satellite Data, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Semantic Neural Radiance Fields for Multi-Date Satellite Data</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- Favicon Stuff -->
  <link rel="icon" type="image/png" href="./static/images/favicon/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/svg+xml" href="./static/images/favicon/favicon.svg" />
  <link rel="shortcut icon" href="./static/images/favicon/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="./static/images/favicon/apple-touch-icon.png" />
  <link rel="manifest" href="./static/images/favicon/site.webmanifest" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <!-- https://github.com/sneas/img-comparison-slider -->
  <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->

      <!-- <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div> -->

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Semantic Neural Radiance Fields for <br>Multi-Date Satellite Data</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Valentin Wagner,</span>
            <span class="author-block">
              Sebastian Bullinger,</span>
            <span class="author-block">
              Christoph Bodensteiner,</span>
            <span class="author-block">
              and Michael Arens</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Fraunhofer Institute of Optronics, System Technologies and Image Exploitation</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this work we propose a satellite specific Neural Radiance
            Fields (NeRF) model capable to obtain a threedimensional
            semantic representation (neural semantic field)
            of the scene. The model derives the output from a set of
            multi-date satellite images with corresponding pixel-wise
            semantic labels. We demonstrate the robustness of our approach
            and its capability to improve noisy input labels. We
            enhance the color prediction by utilizing the semantic information
            to adress temporal image inconsistencies caused
            by non-stationary categories such as vehicles.
          </p>
          <p>
            To facilitate
            further research in this domain, we present a dataset comprising
            manually generated labels for popular multi-view
            satellite images.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <div class="columns">

        <div class="column">
          <div class="content">
            <video id="jax214_rgb" autoplay muted loop playsinline height="100%">
              <source src="./static/videos/jax_214_rgb.webm"
                      type="video/mp4">
            </video>
            <!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/iQ1-orKvd_I?si=9ika5E2Id3ivay9Q&amp;controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>         -->
          </div>
        </div>
  
        <div class="column">
          <div class="content">
            <video id="jax214_semantic" autoplay muted loop playsinline height="100%">
              <source src="./static/videos/jax_214_semantic.webm"
                      type="video/mp4">
            </video>
            <!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/-UcKHpQlntU?si=T7a_rdhMGgoMgLjn&amp;controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>        </div> -->
        </div>

      </div>
    </div>

    
    <p>Color and Semantic Images are rendered in the same inference call using a shared three-dimensional structure.</p>

  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="publication-video">
          <img src="static/images/Pipeline.png" alt="">
        </div>
        <div class="content has-text-justified">
          <p>
            The satellite-domain-adapted outputs (i.e. elements in the blue area) are combined using an
            irradiance lighting model to produce the color rendering as originally proposed by <a href="https://arxiv.org/abs/2203.08896">SatNeRF</a>. Using an additional semantic head (i.e.
            elements in the red area) our proposed method is able to produce a corresponding semantic pixel-wise labeling. We combine this with
            the learned lighting scalar to create a three-dimensional semantic visualization. We introduce a transient regularization loss \(L_t\) to reduce
            artifacts in the learned appearance based on the semantic input data.
          </p>
        </div>
      </div>
    </div> 
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop has-text-justified">

    <h2 class="title">Semantic Neural Radiance Fields for Multi-Date Satellite Data</h2>

    </div>
  </section>


<section class="section">
  <div class="container is-max-desktop has-text-justified">

    <h2 class="title">Transient Regularization</h2>

    <p><b>Issue:</b> Due to the dataset images being captured over a span of time (Multi-Date), each image contains a varying set of moving, transient objects such as vehicles. 
      Neural Radiance Fields reconstruct the pixel colors assuming an inherent multi-view consistency.
      This can cause local inconsistencies and artefacts in the learned color representation as the network tries to average between all given input images.
    </p>

    <p class="mt-1">
      The same parking lot across a series of training images including their capture date:
    </p>
    <div class="columns is-centered is-mobile is-multiline mt-1">
      <div class="column is-half-mobile has-text-centered">
          <img src="./static/images/dataset_transients/JAX_214_005_RGB.jpg" alt="">
          <h5 class="subtitle is-6 mt-2">June 2018</h5>
      </div>
      <div class="column is-half-mobile has-text-centered">
        <img src="./static/images/dataset_transients/JAX_214_008_RGB.jpg" alt="">
        <h5 class="subtitle is-6 mt-2">June 2018</h5>
      </div>
      <div class="column is-half-mobile has-text-centered">
        <img src="./static/images/dataset_transients/JAX_214_012_RGB.jpg" alt="">
        <h5 class="subtitle is-6 mt-2">June 2018</h5>
      </div>
      <div class="column is-half-mobile has-text-centered">
        <img src="./static/images/dataset_transients/JAX_214_015_RGB.jpg" alt="">
        <h5 class="subtitle is-6 mt-2">June 2018</h5>
      </div>
      <div class="column is-half-mobile has-text-centered">
        <img src="./static/images/dataset_transients/JAX_214_016_RGB.jpg" alt="">
        <h5 class="subtitle is-6 mt-2">June 2018</h5>
      </div>
    </div>

    <p>
      <b>Goal:</b> Reduce artefacts caused by moving, transient objects such as vehicles.
    </p>

    <p class="mt-5">
      Analog to <a href="https://nerf-w.github.io/">Nerf-in-the-Wild</a> we propose the use of a learned uncertainty \( \beta(\mathbf{x}, \mathbf{t}_j) \). \(\mathbf{x}\) hereby refers to a 3-dimensional position in the scene 
      and \(\mathbf{t}_j\) is a learned embedding for each training image \(j\). 
      The color loss \(L_{color}\) is modified to include the uncertainty, allowing the network to reduce the impact of pixels belonging to transient objects by increasing the uncertainty \(\beta \).
    </p>

    <p class="mt-3">
      \( \large L_{color}(\mathcal{R}) = \sum_{\mathbf{r} \in \mathcal{R}} \frac{|| \mathbf{c}(\mathbf{r}) - \mathbf{c}_{GT}(\mathbf{r}) ||^2_2}{2\beta'(\mathbf{r})^2} + \left( \frac{\log{\beta'(\mathbf{r}) + \eta}}{2} \right) \)
    </p>

    <p class="mt-5">
      <b>Our Contribution:</b> We propose a transient regularization loss \( L_t \), using existing semantic data to increase uncertainty \(\beta \) for known transient locations based on existing ground truth semantic data.
    </p>

    <p class="mt-3">
      \( \large L_{t}(\mathcal{R}^t) = \sum_{r \in \mathcal{R}^t} || 1.0 - \beta(r)  ||^2_2 
      \text{ with } 
      \mathcal{R}_t = \{\ \mathbf{r} \in \mathcal{R} | semantic_{gt}(\mathbf{r}) = vehicle \} \)
    </p>

    <p class="mt-5">
      <b>Results:</b> We show a strong decrease in artefacts, mainly in parking lots and on top of parking garages.
    </p>

    <div class="columns is-vcentered mt-3">

        <!-- <div class="column">
          <div class="image-comp">
            <div style="background-image: url('./static/images/dataset/JAX_004_012_RGB.jpg')" alt="" class="img background"> </div>
            <div style="background-image: url('./static/images/dataset/JAX_004_012_CLS.jpg')" alt="" class="img foreground"> </div>
            <input type="range" min="1" max="100" value="50" name='slider' class="slider">
            <div class='slider-button'></div>
          </div>
        </div> -->

        <!-- Before/After for JAX068 -->
        <div class="column">
          <img-comparison-slider class="slider-with-animated-handle">
            <figure slot="first" class="before">
              <img width="100%" src="./static/images/car_reg/JAX_068_010_RGB_-1_NCR.png">
              <figcaption>SatNeRF</figcaption>
            </figure>

            <figure slot="second" class="after">
              <img width="100%" src="./static/images/car_reg/JAX_068_010_RGB_-1_WCR.png">
              <figcaption>Ours</figcaption>
            </figure>

            <svg slot="handle" class="custom-animated-handle" xmlns="http://www.w3.org/2000/svg" width="100" viewBox="-8 -3 16 6">
              <path stroke="#fff" d="M -5 -2 L -7 0 L -5 2 M -5 -2 L -5 2 M 5 -2 L 7 0 L 5 2 M 5 -2 L 5 2" stroke-width="1" fill="#fff" vector-effect="non-scaling-stroke"></path>
            </svg>
          </img-comparison-slider>
        </div>

        <!-- Before/After for JAX214 -->
        <div class="column">
          <img-comparison-slider class="slider-with-animated-handle">
            <figure slot="first" class="before">
              <img width="100%" src="./static/images/car_reg/JAX_214_019_RGB_-1_NCR.png">
              <figcaption>SatNeRF</figcaption>
            </figure>

            <figure slot="second" class="after">
              <img width="100%" src="./static/images/car_reg/JAX_214_019_RGB_-1_WCR.png">
              <figcaption>Ours</figcaption>
            </figure>

            <svg slot="handle" class="custom-animated-handle" xmlns="http://www.w3.org/2000/svg" width="100" viewBox="-8 -3 16 6">
              <path stroke="#fff" d="M -5 -2 L -7 0 L -5 2 M -5 -2 L -5 2 M 5 -2 L 7 0 L 5 2 M 5 -2 L 5 2" stroke-width="1" fill="#fff" vector-effect="non-scaling-stroke"></path>
            </svg>
          </img-comparison-slider>
        </div>

    </div>

    <div class="columns has-text-centered  is-hidden-mobile">
      <div class="column">
        <h5 class="subtitle is-6">JAX 068</h5>
      </div>
      <div class="column">
        <h5 class="subtitle is-6">JAX 214</h5>
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <h2 class="title">Dataset</h2>

    <p>
      We release a dataset comprising of high-quality semantic annotations for the main Area-of-Interest for four scenes from the <a href="https://ieee-dataport.org/open-access/data-fusion-contest-2019-dfc2019">DFC-2019 Track-3 Dataset</a>.
      To create the annotations we manually refine initial rough estimates of a user guided, class agnostic foundation model for semantic segmentation.
    </p>
    <p class="mt-2">
      The dataset covers the five semantic classes: <span class="is-italic">Ground, Water, Vegetation, Building</span> and <span class="is-italic">Vehicles</span>.
    </p>

    <!-- Dataset Link. -->
    <div class="mt-3">
      <span class="link-block">
        <a href="https://github.com/google/nerfies/releases/tag/0.1"
            class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
              <i class="far fa-images"></i>
          </span>
          <span>Data</span>
          </a>
      </span>
    </div>
    

    <div class="columns is-centered is-mobile is-multiline mt-3"> 
      
      <div class="column is-half-mobile has-text-centered">
          <img src="./static/images/dataset/JAX_004_012_RGB.jpg" alt="">
          <img src="./static/images/dataset/JAX_004_012_CLS.jpg" alt="" class="mt-3">
          <h5 class="subtitle is-6 mt-2">JAX 004</h5>
      </div>
      <div class="column is-half-mobile has-text-centered">
        <img src="./static/images/dataset/JAX_068_012_RGB.jpg" alt="">
        <img src="./static/images/dataset/JAX_068_012_CLS.jpg" alt="" class="mt-3">
        <h5 class="subtitle is-6 mt-2">JAX 068</h5>
      </div>
      <div class="column is-half-mobile has-text-centered">
        <img src="./static/images/dataset/JAX_214_012_RGB.jpg" alt="">
        <img src="./static/images/dataset/JAX_214_012_CLS.jpg" alt="" class="mt-3">
        <h5 class="subtitle is-6 mt-2">JAX 214</h5>
      </div>
      <div class="column is-half-mobile has-text-centered">
        <img src="./static/images/dataset/JAX_260_012_RGB.jpg" alt="">
        <img src="./static/images/dataset/JAX_260_012_CLS.jpg" alt="" class="mt-3">
        <h5 class="subtitle is-6 mt-2">JAX 260</h5>
      </div>

    </div>

  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>Citation information </code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            This website is made using the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> template.
            <br>
            Favicon icon used from <a href="https://www.flaticon.com/free-icons/globe" title="Flaticon.com">Freepik - Flaticon</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
